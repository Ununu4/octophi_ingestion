# ğŸ™ OCTOPHI Ingestion System V1

**Modular Schema-Driven ETL + Normalization Pipeline for Monet (MCA Domain)**

Version: 1.0  
Author: Otto / Octophi

---

## Overview

OCTOPHI is a universal, schema-driven ingestion engine that:

- âœ… Loads data from **messy CSV/XLSX files**
- âœ… Maps fuzzy headers to **canonical schema fields**
- âœ… Applies **type-specific normalization** (phones, emails, dates, etc.)
- âœ… Handles **extra columns** via appendix table
- âœ… Produces **clean, normalized data** ready for database insertion
- âœ… Supports **multiple domains** (currently: Monet/MCA)

---

## Directory Structure

```
octophi_ingestion/
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ monet/
â”‚       â”œâ”€â”€ schema.json      # Canonical schema definition
â”‚       â””â”€â”€ fuzzy.json       # Header mapping rules
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ schema_loader.py     # Schema parsing
â”‚   â”œâ”€â”€ header_mapper.py     # Fuzzy header matching
â”‚   â”œâ”€â”€ type_normalizer.py   # Type-specific cleaning
â”‚   â”œâ”€â”€ deep_cleaner.py      # Main cleaning orchestration
â”‚   â”œâ”€â”€ ingest_engine.py     # Database operations
â”‚   â””â”€â”€ cli.py               # Command-line interface
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py            # Logging utilities
â”‚   â””â”€â”€ file_ops.py          # File operations
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_schema_loader.py
â”‚   â”œâ”€â”€ test_header_mapper.py
â”‚   â””â”€â”€ test_normalization.py
â”‚
â””â”€â”€ docs/
    â””â”€â”€ OCTOPHI_INGESTION_V1_SPEC.md
```

---

## Quick Start

### 1. Installation

No external dependencies required beyond Python 3.9+ standard library and pandas:

```bash
pip install pandas openpyxl
```

### 2. Basic Usage

```bash
# Navigate to project directory
cd octophi_ingestion

# Run ingestion
python -m ingestion.cli \
    --schema monet \
    --file /path/to/input.xlsx \
    --db /path/to/database.sqlite \
    --source "Broker Name"
```

### 3. Full Command Options

```bash
python -m ingestion.cli \
    --schema monet \
    --file input.csv \
    --db monet.sqlite \
    --source "Source Name" \
    --upload-tag "2025_12_08_batch_1" \
    --create-indexes \
    --log-file ingestion.log \
    --dry-run
```

**Arguments:**

| Argument | Required | Description |
|----------|----------|-------------|
| `--schema` | Yes | Schema name (e.g., "monet") |
| `--file` | Yes | Input CSV or XLSX file |
| `--db` | Yes | SQLite database path |
| `--source` | Yes | Source name for this data |
| `--upload-tag` | No | Custom upload tag (default: timestamp) |
| `--create-indexes` | No | Create performance indexes |
| `--log-file` | No | Log to file (default: console only) |
| `--dry-run` | No | Preview only, don't insert data |

---

## Features

### 1. Schema-Driven Architecture

All field definitions, types, and relationships are defined in `schemas/monet/schema.json`:

```json
{
  "schema_name": "monet_merchant",
  "version": "1.0",
  "entities": {
    "lead": {
      "fields": {
        "business_legal_name": { "type": "string", "required": true },
        "phone_raw": { "type": "phone" },
        "phone_clean": { "type": "phone_clean", "derived_from": "phone_raw" }
      }
    }
  }
}
```

### 2. Fuzzy Header Mapping

Maps messy CSV headers to canonical fields via `schemas/monet/fuzzy.json`:

```json
{
  "business_legal_name": [
    "business name", "legal name", "company name", "merchant name"
  ],
  "phone_raw": [
    "phone", "phone number", "telephone", "business phone"
  ]
}
```

**Examples:**
- `"Business Name"` â†’ `business_legal_name`
- `"Ph one"` â†’ `phone_raw`
- `"LEGAL NAME"` â†’ `business_legal_name`

### 3. Type-Specific Normalization

Automatic normalization based on field types:

| Type | Normalization |
|------|---------------|
| `phone` | Digits only: `(555) 123-4567` â†’ `5551234567` |
| `email` | Lowercase: `USER@EXAMPLE.COM` â†’ `user@example.com` |
| `state` | Uppercase 2-letter: `ca` â†’ `CA` |
| `zip` | First 5 digits: `12345-6789` â†’ `12345` |
| `id_number` | Digits only: `123-45-6789` â†’ `123456789` |
| `date` | ISO format: `01/15/2020` â†’ `2020-01-15` |

### 4. Derived Fields

Automatically derive fields from source fields:

- `phone_clean` â† `phone_raw` (digits only)
- `second_phone_clean` â† `second_phone_raw`
- `owner_phone_clean` â† `owner_phone`
- `soc` â† `sic` (industry mapping)

### 5. Appendix System

Extra columns not in schema are automatically stored in `lead_appendix_kv` table:

| lead_id | column_name | value | upload_tag |
|---------|-------------|-------|------------|
| 1 | offer | $50K / 1.25 / 6mo | 20251208_101530 |
| 1 | bank | Chase | 20251208_101530 |

### 6. Placeholder Detection

Automatically converts placeholder values to `NULL`:

- `NA`, `N/A`, `NONE`, `NULL`, `NIL`
- `UNKNOWN`, `UNSPECIFIED`, `TBD`, `NAN`

---

## Schema Reference (Monet)

### Lead Entity Fields

- `business_legal_name` (required)
- `dba`
- `business_address`, `business_city`, `business_state`, `zip`
- `phone_raw`, `phone_clean` (derived)
- `second_phone_raw`, `second_phone_clean` (derived)
- `business_email`, `business_second_email`
- `start_date`
- `tax_id`
- `sic`, `soc` (derived)
- `source` (required)

### Owner Entity Fields

- `owner_name`
- `dob`
- `ssn`
- `owner_address`, `owner_city`, `owner_state`, `owner_zip`
- `owner_email`, `owner_second_email`
- `owner_phone`, `owner_phone_clean` (derived)

### Relationships

- **Lead â†” Owner**: One-to-one (each lead has one owner)
- **Source â†” Lead**: One-to-many (one source has many leads)

---

## Testing

### Run All Tests

```bash
# Test schema loader
python octophi_ingestion/tests/test_schema_loader.py

# Test header mapper
python octophi_ingestion/tests/test_header_mapper.py

# Test normalization
python octophi_ingestion/tests/test_normalization.py
```

### Run Individual Module Tests

```python
from ingestion.schema_loader import Schema
from ingestion.header_mapper import HeaderMapper
from ingestion.type_normalizer import Normalizer

# Test schema
schema = Schema('schemas/monet/schema.json')
print(schema.fields('lead'))

# Test mapper
mapper = HeaderMapper('schemas/monet/fuzzy.json')
print(mapper.get_canonical_field('Business Name'))

# Test normalizer
normalizer = Normalizer()
print(normalizer.normalize('(555) 123-4567', 'phone'))
```

---

## Database Schema

The system creates/uses these tables:

### `sources`
- `id` (PK)
- `name` (UNIQUE)
- `notes`
- `created_at`

### `leads`
- `id` (PK)
- `business_legal_name`, `dba`, `business_address`, ...
- `phone_raw`, `phone_clean`, `second_phone_raw`, `second_phone_clean`
- `business_email`, `business_second_email`
- `start_date`, `tax_id`, `soc`
- `source_id` (FK â†’ sources)
- `created_at`, `updated_at`

### `owners`
- `id` (PK)
- `lead_id` (FK â†’ leads, UNIQUE)
- `owner_name`, `dob`, `ssn`
- `owner_address`, `owner_city`, `owner_state`, `owner_zip`
- `owner_email`, `owner_second_email`
- `owner_phone`, `owner_phone_clean`
- `created_at`, `updated_at`

### `lead_appendix_kv`
- `id` (PK)
- `lead_id` (FK â†’ leads)
- `source_id` (FK â†’ sources)
- `upload_tag`
- `original_row_number`
- `column_name`
- `value`
- `created_at`

---

## Examples

### Example 1: Basic Ingestion

```bash
python -m ingestion.cli \
    --schema monet \
    --file broker_leads.xlsx \
    --db monet_production.sqlite \
    --source "XYZ Broker"
```

**Output:**
```
======================================================================
ğŸ™ OCTOPHI INGESTION SYSTEM V1
======================================================================

INFO | Validating input file: broker_leads.xlsx
INFO | âœ“ File validated: 2.45 MB
INFO | Loading schema: monet
INFO | âœ“ Schema loaded: monet_merchant v1.0
INFO | Loading fuzzy mappings...
INFO | âœ“ Fuzzy mappings loaded
INFO | Initializing deep cleaner...

INFO | ğŸ§¹ Cleaning file: broker_leads.xlsx
----------------------------------------------------------------------
ğŸ“‹ Loaded 500 rows with 35 columns
âœ“ Mapped 27 known fields
ğŸ“¦ Found 8 extra columns (will store in appendix): offer, bank, ...
âœ… Cleaning complete: 500 leads, 500 owners, 4000 appendix rows
----------------------------------------------------------------------

ğŸ“Š CLEANING SUMMARY
----------------------------------------------------------------------
Leads:         500 rows
Owners:        500 rows
Appendix:    4,000 rows
----------------------------------------------------------------------

INFO | Connecting to database: monet_production.sqlite
ğŸš€ Starting ingestion...
   Source: XYZ Broker
   Upload tag: 20251208_143052
   Records: 500 leads, 500 owners, 4000 appendix rows
âœ“ Source ID: 12
âœ“ Inserted 500 leads
âœ“ Inserted 500 owners
âœ“ Inserted 4,000 appendix rows
âœ… Ingestion complete!

======================================================================
âœ… INGESTION COMPLETE
======================================================================
Source:      XYZ Broker
Upload tag:  20251208_143052
Database:    monet_production.sqlite
Leads:       500
Owners:      500
Appendix:    4,000
======================================================================
```

### Example 2: Dry Run (Preview Only)

```bash
python -m ingestion.cli \
    --schema monet \
    --file test_data.csv \
    --db monet.sqlite \
    --source "Test" \
    --dry-run
```

### Example 3: With Indexes

```bash
python -m ingestion.cli \
    --schema monet \
    --file large_feed.csv \
    --db monet.sqlite \
    --source "Big Data Feed" \
    --create-indexes
```

---

## Extending to New Domains

To add support for a new domain (e.g., "pharmacy"):

1. Create `schemas/pharmacy/schema.json`
2. Create `schemas/pharmacy/fuzzy.json`
3. Run: `python -m ingestion.cli --schema pharmacy ...`

The system automatically loads the appropriate schema!

---

## Design Principles

1. **Schema-Driven**: No hardcoded field names in code
2. **Modular**: Each component is independent and testable
3. **Extensible**: Add new domains by adding schema files
4. **Safe**: Validates data before insertion
5. **Transparent**: Clear logging at every step
6. **Flexible**: Extra columns preserved via appendix

---

## Troubleshooting

### Issue: "Schema file not found"
**Solution:** Ensure you're running from `octophi_ingestion/` directory or use absolute paths

### Issue: Required field validation fails
**Solution:** Check that CSV has `business_legal_name` and `source` columns (or fuzzy matches)

### Issue: No headers mapped
**Solution:** Add your header variants to `schemas/monet/fuzzy.json`

---

## Performance

- **Small files** (<10K rows): ~5-10 seconds
- **Medium files** (10K-100K rows): ~30-60 seconds
- **Large files** (>100K rows): ~2-5 minutes

**Optimization tips:**
- Use `--create-indexes` for large databases
- Process files in batches if >500K rows
- Use SSD for database storage

---

## Future Enhancements

- [ ] Support for PostgreSQL/MySQL
- [ ] Web UI for drag-and-drop ingestion
- [ ] Advanced SICâ†’SOC mapping
- [ ] Duplicate detection options
- [ ] Data quality scoring
- [ ] Support for JSON/XML input
- [ ] Streaming mode for massive files

---

## License

Internal use only - Octophi/Monet Capital

---

## Support

For questions or issues, contact the development team.

**Built with â¤ï¸ by Otto @ Octophi**




